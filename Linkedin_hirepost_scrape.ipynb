{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webdriver-manager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the login credentials\n",
    "print(\"Please enter your LinkedIn credentials:\")\n",
    "print(\"Email: \")\n",
    "username = input()\n",
    "print(\"Password: \")\n",
    "password = input()\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "service = Service(executable_path=r\"C:\\Users\\snehi\\Desktop\\Linkedin_extract\\chromedriver.exe\") # latest 132v chrome driver\n",
    "driver = webdriver.Chrome(service=service)\n",
    "#driver = webdriver.Chrome(executable_path=r\"C:\\Users\\snehi\\Desktop\\Linkedin_extract\\chromedriver.exe\") \n",
    "driver.maximize_window()\n",
    "\n",
    "# Navigate to the LinkedIn login page\n",
    "driver.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "# Find the input fields and enter the login credentials\n",
    "username_field = driver.find_element(By.ID, \"username\")\n",
    "username_field.send_keys(username)\n",
    "\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "password_field.send_keys(password)\n",
    "\n",
    "# Submit the login form\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the page to load after login\n",
    "time.sleep(5)\n",
    "\n",
    "# Wait for the page to load after login\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    # Add more user-agents\n",
    "]\n",
    "headers = {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "\n",
    "print(\"LinkedIn LOGGED IN Successfully..................START Extracting the postings\")\n",
    "\n",
    "\n",
    "### CUSTOM RUNNING VERSION (just extracts linkedin job posts, but NOT External LINKS )\n",
    "### This below script extracts the job postings from specific LinkedIn search results page with a given post date\n",
    "\n",
    "urllink = 'https://www.linkedin.com/search/results/content/?datePosted=%22past-24h%22&keywords=(%22Data%20Analyst%22%20OR%20%22Business%20Analyst%22)%20AND%20(%22Hiring%22%20OR%20%22Looking%20for%22)&origin=GLOBAL_SEARCH_HEADER&sid=%40%2CL&sortBy=%22relevance%22'\n",
    "post_date = \"2025-01-01\"  # User input for the post date\n",
    "\n",
    "driver.get(urllink)\n",
    "\n",
    "\n",
    "# Wait for page to load\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# Function to extract job postings\n",
    "def extract_postings(soup):\n",
    "    extract_posting = soup.find_all('div', class_='fie-impression-container')\n",
    "    postings = []\n",
    "    for post in extract_posting:\n",
    "        job_title_element = post.find('h2', class_='update-components-entity__title')\n",
    "        if job_title_element:\n",
    "            job_title = job_title_element.text.strip()\n",
    "        else:\n",
    "            job_title = ''\n",
    "        \n",
    "        location_element = post.find('h3', class_='update-components-entity__description')\n",
    "        if location_element:\n",
    "            location = location_element.text.strip()\n",
    "            location_parts = location.split(', ')\n",
    "            city = location_parts[0]\n",
    "            state = location_parts[1] if len(location_parts) > 1 else ''\n",
    "            country = location_parts[2] if len(location_parts) > 2 else ''\n",
    "        else:\n",
    "            city = state = country = ''\n",
    "        \n",
    "        company_element = post.find('h3', class_='update-components-entity__subtitle')\n",
    "        if company_element:\n",
    "            company = company_element.text.strip().replace('Job by ', '')\n",
    "            company_link = f\"https://www.linkedin.com/company/{company.replace(' ', '-')}/\"\n",
    "        else:\n",
    "            company = ''\n",
    "        \n",
    "        post_hour_text_element = post.find('a', class_='app-aware-link update-components-actor__sub-description-link')\n",
    "        if post_hour_text_element:\n",
    "            post_hour_text = post_hour_text_element.text.strip()\n",
    "            post_hour = re.search(r'\\d+', post_hour_text).group()\n",
    "            post_hour = int(post_hour)\n",
    "        else:\n",
    "            post_hour = ''\n",
    "        \n",
    "        hiring_employee_name_element = post.find('span', class_='update-components-actor__name')\n",
    "        if hiring_employee_name_element:\n",
    "            hiring_employee_name = hiring_employee_name_element.text.strip()\n",
    "        else:\n",
    "            hiring_employee_name = ''\n",
    "        \n",
    "        hiring_employee_profile_link_element = post.find('a', class_='app-aware-link update-components-actor__image relative')\n",
    "        if hiring_employee_profile_link_element:\n",
    "            hiring_employee_profile_link = hiring_employee_profile_link_element['href']\n",
    "        else:\n",
    "            hiring_employee_profile_link = ''\n",
    "        \n",
    "        job_link_element = post.find('a', class_='app-aware-link update-components-entity__content display-flex')\n",
    "        if job_link_element:\n",
    "            job_link = job_link_element['href']\n",
    "        else:\n",
    "            # Check for the new format \n",
    "            job_link_element_new = post.find('a', class_='app-aware-link  update-components-article__meta flex-grow-1 full-width tap-target display-flex justify-space-between align-items-flex-start') \n",
    "            if job_link_element_new: \n",
    "                job_link = job_link_element_new['href'] \n",
    "            else: \n",
    "                job_link = ''\n",
    "\n",
    "        posting = {\n",
    "            'title': job_title,\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'country': country,\n",
    "            'company_link': company_link,\n",
    "            'company': company,\n",
    "            'Post hour': post_hour,\n",
    "            'hiring/employee_name': hiring_employee_name,\n",
    "            'hiring/employee_profile_link':  hiring_employee_profile_link,\n",
    "            'post_date': post_date,\n",
    "            'Job_link':  job_link\n",
    "        }\n",
    "        \n",
    "        print(posting)\n",
    "        # Only add posting if job_link is available\n",
    "        if job_link:\n",
    "            postings.append(posting)\n",
    "    \n",
    "    return postings\n",
    "\n",
    "\n",
    "# Initialize CSV writer\n",
    "import csv\n",
    "with open('linkedin_hiringposts.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['title', 'city', 'state', 'country', 'company_link', 'company', 'Post hour', 'hiring/employee_name', 'hiring/employee_profile_link', 'post_date', 'Job_link']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "# Initialize postings list\n",
    "postings = []\n",
    "\n",
    "\n",
    "# Initial extraction\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "new_postings = extract_postings(soup)\n",
    "for posting in new_postings:\n",
    "    if posting not in postings:\n",
    "        postings.append(posting)\n",
    "\n",
    "\n",
    "# Scroll and extract more postings\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "scroll_count = 0\n",
    "max_scrolls = 10\n",
    "\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(3)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    scroll_count += 1\n",
    "\n",
    "\n",
    "    if new_height == last_height or scroll_count >= max_scrolls:\n",
    "        break\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    new_postings = extract_postings(soup)\n",
    "    for posting in new_postings:\n",
    "        if posting not in postings:\n",
    "            postings.append(posting)\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "# Write postings to CSV\n",
    "with open('linkedin_hiringposts.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['title', 'city', 'state', 'country', 'company_link', 'company', 'Post hour', 'hiring/employee_name', 'hiring/employee_profile_link', 'post_date', 'Job_link']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    for posting in postings:\n",
    "        writer.writerow(posting)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
